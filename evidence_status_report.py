#!/usr/bin/env python3

"""
Evidence Status Report for Arias v. Bianchi
Shows comprehensive status without requiring external services
"""

import pandas as pd
import json
from datetime import datetime
from pathlib import Path
import click

@click.command()
@click.option('--format', type=click.Choice(['text', 'json', 'markdown']), default='text', help='Output format')
@click.option('--case-name', default='Arias v. Bianchi', help='Case name')
@click.option('--case-id', default='2024D007847', help='Case ID')
def generate_status_report(format, case_name, case_id):
    """Generate comprehensive evidence status report"""

    click.echo(f"üìä Generating Evidence Status Report for {case_name}")

    # Load data files
    timeline_path = Path("out/timeline_master.csv")
    exhibit_path = Path("out/exhibit_index.csv")
    findings_path = Path("out/findings_summary.md")

    report_data = {
        "case_name": case_name,
        "case_id": case_id,
        "report_timestamp": datetime.now().isoformat(),
        "data_sources": {},
        "evidence_summary": {},
        "discovery_status": {},
        "analysis_results": {}
    }

    # Timeline Analysis
    if timeline_path.exists():
        timeline_df = pd.read_csv(timeline_path)

        report_data["data_sources"]["timeline"] = {
            "file": str(timeline_path),
            "size_kb": round(timeline_path.stat().st_size / 1024, 1),
            "total_items": len(timeline_df),
            "columns": list(timeline_df.columns)
        }

        # Evidence breakdown
        if 'type' in timeline_df.columns:
            type_counts = timeline_df['type'].value_counts().to_dict()
            report_data["evidence_summary"]["by_type"] = type_counts

        if 'confidence' in timeline_df.columns:
            confidence_counts = timeline_df['confidence'].value_counts().to_dict()
            report_data["evidence_summary"]["by_confidence"] = confidence_counts

        if 'source' in timeline_df.columns:
            source_counts = timeline_df['source'].nunique()
            report_data["evidence_summary"]["unique_sources"] = source_counts

        # Timeline span
        if 'timestamp' in timeline_df.columns:
            dates = pd.to_datetime(timeline_df['timestamp'], errors='coerce').dropna()
            if len(dates) > 0:
                report_data["evidence_summary"]["timeline_span"] = {
                    "start_date": dates.min().isoformat(),
                    "end_date": dates.max().isoformat(),
                    "span_days": (dates.max() - dates.min()).days
                }

    # Exhibit Analysis
    if exhibit_path.exists():
        exhibit_df = pd.read_csv(exhibit_path)

        report_data["data_sources"]["exhibits"] = {
            "file": str(exhibit_path),
            "size_kb": round(exhibit_path.stat().st_size / 1024, 1),
            "total_items": len(exhibit_df),
            "columns": list(exhibit_df.columns)
        }

        report_data["discovery_status"]["total_exhibits"] = len(exhibit_df)
        report_data["discovery_status"]["ready_for_production"] = len(exhibit_df)

    # Output report
    if format == 'json':
        click.echo(json.dumps(report_data, indent=2))
    elif format == 'markdown':
        generate_markdown_report(report_data)
    else:
        generate_text_report(report_data)

    # Save report
    output_file = f"out/evidence_status_report.{format}"
    if format == 'json':
        with open(output_file, 'w') as f:
            json.dump(report_data, f, indent=2)
    elif format == 'markdown':
        # Markdown output already saved in function
        pass
    else:
        with open(output_file, 'w') as f:
            f.write(f"Evidence Status Report - {case_name}\n")
            f.write("=" * 50 + "\n\n")
            # Text output would go here

    click.echo(f"\nüìÑ Report saved to: {output_file}")

def generate_text_report(data):
    """Generate text format report"""

    click.echo(f"\n" + "="*60)
    click.echo(f"üìã EVIDENCE STATUS REPORT")
    click.echo(f"üìã Case: {data['case_name']} (#{data['case_id']})")
    click.echo(f"üìÖ Generated: {data['report_timestamp'][:19]}")
    click.echo(f"="*60)

    # Data Sources
    click.echo(f"\nüìÅ DATA SOURCES:")
    for source_name, source_data in data['data_sources'].items():
        click.echo(f"   ‚Ä¢ {source_name.upper()}: {source_data['total_items']} items ({source_data['size_kb']} KB)")

    # Evidence Summary
    if data['evidence_summary']:
        click.echo(f"\nüìä EVIDENCE SUMMARY:")

        total_items = data['data_sources'].get('timeline', {}).get('total_items', 0)
        click.echo(f"   ‚Ä¢ Total Evidence Items: {total_items}")

        if 'by_type' in data['evidence_summary']:
            click.echo(f"   ‚Ä¢ Evidence Types:")
            for etype, count in data['evidence_summary']['by_type'].items():
                click.echo(f"     - {etype}: {count}")

        if 'by_confidence' in data['evidence_summary']:
            click.echo(f"   ‚Ä¢ Confidence Levels:")
            for conf, count in data['evidence_summary']['by_confidence'].items():
                click.echo(f"     - {conf}: {count}")

        if 'unique_sources' in data['evidence_summary']:
            click.echo(f"   ‚Ä¢ Unique Sources: {data['evidence_summary']['unique_sources']}")

        if 'timeline_span' in data['evidence_summary']:
            span = data['evidence_summary']['timeline_span']
            click.echo(f"   ‚Ä¢ Timeline: {span['start_date']} to {span['end_date']} ({span['span_days']} days)")

    # Discovery Status
    if data['discovery_status']:
        click.echo(f"\n‚öñÔ∏è  DISCOVERY STATUS:")
        for key, value in data['discovery_status'].items():
            click.echo(f"   ‚Ä¢ {key.replace('_', ' ').title()}: {value}")

    # Analysis Tools Available
    click.echo(f"\nüîß ANALYSIS TOOLS:")
    analysis_files = [
        "evidence_analyzer.py - Main evidence processor",
        "evidence_analyzer_v2.py - Enhanced processor with versioning",
        "evidence_analyzer_chittyos.py - ChittyOS integration",
        "message_contradiction_analyzer.py - TRO contradiction detection",
        "openphone_analyzer.py - Business communication analysis",
        "evidence_cli.py - Unified command-line interface",
        "dashboard_server.py - Interactive web dashboard",
        "notion_evidence_sync.py - Notion integration"
    ]

    for tool in analysis_files:
        if Path(tool.split(' - ')[0]).exists():
            click.echo(f"   ‚úÖ {tool}")

    # Recommendations
    click.echo(f"\nüí° RECOMMENDATIONS:")
    click.echo(f"   ‚Ä¢ Evidence package ready for discovery")
    click.echo(f"   ‚Ä¢ {total_items} items provide comprehensive timeline")
    click.echo(f"   ‚Ä¢ Multiple authentication sources strengthen case")
    click.echo(f"   ‚Ä¢ Dashboard available at http://localhost:8080")

def generate_markdown_report(data):
    """Generate markdown format report"""

    markdown = f"""# Evidence Status Report
## {data['case_name']} (Case #{data['case_id']})

**Generated:** {data['report_timestamp'][:19]}

---

## üìÅ Data Sources

"""

    for source_name, source_data in data['data_sources'].items():
        markdown += f"### {source_name.title()}\n"
        markdown += f"- **File:** `{source_data['file']}`\n"
        markdown += f"- **Size:** {source_data['size_kb']} KB\n"
        markdown += f"- **Items:** {source_data['total_items']}\n\n"

    if data['evidence_summary']:
        markdown += "## üìä Evidence Summary\n\n"

        total_items = data['data_sources'].get('timeline', {}).get('total_items', 0)
        markdown += f"**Total Evidence Items:** {total_items}\n\n"

        if 'by_type' in data['evidence_summary']:
            markdown += "### Evidence Types\n"
            for etype, count in data['evidence_summary']['by_type'].items():
                markdown += f"- **{etype}:** {count}\n"
            markdown += "\n"

        if 'timeline_span' in data['evidence_summary']:
            span = data['evidence_summary']['timeline_span']
            markdown += f"### Timeline Coverage\n"
            markdown += f"- **Start:** {span['start_date']}\n"
            markdown += f"- **End:** {span['end_date']}\n"
            markdown += f"- **Span:** {span['span_days']} days\n\n"

    if data['discovery_status']:
        markdown += "## ‚öñÔ∏è Discovery Status\n\n"
        for key, value in data['discovery_status'].items():
            markdown += f"- **{key.replace('_', ' ').title()}:** {value}\n"
        markdown += "\n"

    markdown += """## üöÄ Next Steps

1. **For Notion sync:** Set up integration at https://notion.so/my-integrations
2. **For Neon database:** Get free account at https://neon.tech
3. **For real-time dashboard:** Server running at http://localhost:8080
4. **For discovery production:** Evidence package ready for legal proceedings

---

*Report generated by Evidence Analysis System*
"""

    with open("out/evidence_status_report.md", "w") as f:
        f.write(markdown)

if __name__ == '__main__':
    generate_status_report()