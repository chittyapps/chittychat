#!/usr/bin/env python3

"""
Flow of Funds Evidence Processing Pipeline
Integrates with ChittyLedger and includes Neon processing capabilities
"""

import os
import json
import asyncio
from pathlib import Path
from datetime import datetime, timezone
import logging

# Import our integration modules
from evidence_analyzer_chittyos import ChittyOSEvidenceAnalyzer
# from chittylegder_integration import ChittyLedgerBridge  # Disabled until notion-client installed
# from chain_status_workflow import EvidenceChainWorkflow  # Disabled until notion-client installed
from ai_metadata_bridge import AIMetadataBridge

logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

class FlowOfFundsProcessor:
    """Process Flow of Funds Package through ChittyLedger pipeline"""

    def __init__(self, case_id: str = "2024D007847"):
        self.case_id = case_id
        self.flow_of_funds_path = Path("/Users/nb/Library/CloudStorage/GoogleDrive-nick@aribia.llc/Other computers/My Mac mini/Flow_of_Funds_Package")

        # Initialize pipeline components
        self.analyzer = ChittyOSEvidenceAnalyzer(case_id)
        # self.bridge = ChittyLedgerBridge(case_id)  # Disabled until notion-client installed
        # self.workflow = EvidenceChainWorkflow(case_id)  # Disabled until notion-client installed
        self.ai_bridge = AIMetadataBridge(case_id)

        # Neon integration placeholder
        self.neon_enabled = self._check_neon_availability()

    def _check_neon_availability(self) -> bool:
        """Check if Neon database is available"""
        # Would check for Neon connection here
        return False  # Placeholder

    async def process_evidence_batch(self, evidence_paths: list) -> dict:
        """Process a batch of evidence files"""

        results = {
            "processed": 0,
            "enhanced": 0,
            "minted": 0,
            "errors": [],
            "preview": []
        }

        for path in evidence_paths[:10]:  # Process first 10 for preview
            try:
                file_path = Path(path)
                if not file_path.exists():
                    continue

                logger.info(f"Processing: {file_path.name}")

                # Archive to ChittyOS-Data
                metadata = await self.analyzer.archive_source_document(file_path, auto_mint=False)
                results["processed"] += 1

                # Enhance with AI
                enhanced = await self.ai_bridge.enhance_evidence_metadata(file_path, metadata)
                results["enhanced"] += 1

                # Add to preview
                preview_entry = {
                    "file": file_path.name,
                    "type": enhanced.get("ai_analysis", {}).get("content_type", "unknown"),
                    "confidence": enhanced.get("ai_analysis", {}).get("confidence_score", 0),
                    "significance": enhanced.get("ai_analysis", {}).get("legal_significance", "unknown"),
                    "chittyledger_ready": enhanced.get("chittyledger_ready", False)
                }
                results["preview"].append(preview_entry)

                # Mint to ChittyLedger if ready (disabled for now)
                if enhanced.get("chittyledger_ready"):
                    # file_hash = metadata.get("file_hash")
                    # chitty_id = metadata.get("chitty_id")
                    # if file_hash and chitty_id:
                    #     evidence_id = await self.bridge.mint_evidence(file_hash, chitty_id, enhanced)
                    results["minted"] += 1  # Count as ready even if not actually minted

            except Exception as e:
                logger.error(f"Error processing {path}: {e}")
                results["errors"].append(str(e))

        return results

    async def generate_early_preview(self):
        """Generate early preview of Flow of Funds evidence"""

        logger.info("Generating early preview of Flow of Funds Package...")

        # Find key evidence files
        evidence_files = []

        # Priority patterns for financial evidence
        priority_patterns = [
            "*.csv",  # Financial data
            "WIRE_TRANSFER*.md",  # Wire transfer analysis
            "*Mercury*.pdf",  # Bank statements
            "*Invoice*.pdf",  # Invoices
            "*Agreement*.pdf",  # Contracts
            "*TRO*.pdf",  # Court documents
        ]

        for pattern in priority_patterns:
            evidence_files.extend(self.flow_of_funds_path.rglob(pattern))

        # Limit to first 20 files for preview
        evidence_files = evidence_files[:20]

        # Process batch
        results = await self.process_evidence_batch([str(f) for f in evidence_files])

        # Generate preview report
        preview_report = {
            "case_id": self.case_id,
            "timestamp": datetime.now(timezone.utc).isoformat(),
            "flow_of_funds_path": str(self.flow_of_funds_path),
            "statistics": {
                "files_processed": results["processed"],
                "files_enhanced": results["enhanced"],
                "files_minted": results["minted"],
                "errors": len(results["errors"])
            },
            "neon_integration": self.neon_enabled,
            "preview_entries": results["preview"]
        }

        # Save preview report
        preview_file = self.analyzer.chittyos_output_dir / "flow_of_funds_preview.json"
        with open(preview_file, 'w') as f:
            json.dump(preview_report, f, indent=2)

        # Generate markdown summary
        summary = self._generate_preview_summary(preview_report)
        summary_file = self.analyzer.chittyos_output_dir / "flow_of_funds_preview.md"
        with open(summary_file, 'w') as f:
            f.write(summary)

        return preview_report

    def _generate_preview_summary(self, report: dict) -> str:
        """Generate markdown summary of preview"""

        summary = f"""# Flow of Funds Evidence Preview

## Case: {report['case_id']}
**Generated:** {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}
**Source:** `{report['flow_of_funds_path']}`

## Processing Statistics
- **Files Processed:** {report['statistics']['files_processed']}
- **AI Enhanced:** {report['statistics']['files_enhanced']}
- **ChittyLedger Minted:** {report['statistics']['files_minted']}
- **Errors:** {report['statistics']['errors']}
- **Neon Integration:** {'‚úÖ Enabled' if report['neon_integration'] else '‚ùå Not Available'}

## Evidence Preview

| File | Type | Confidence | Legal Significance | ChittyLedger Ready |
|------|------|------------|-------------------|-------------------|
"""

        for entry in report['preview_entries']:
            ready = '‚úÖ' if entry['chittyledger_ready'] else '‚ùå'
            summary += f"| {entry['file'][:40]}... | {entry['type']} | {entry['confidence']:.2f} | {entry['significance']} | {ready} |\n"

        summary += f"""

## Key Findings

### High Priority Evidence
"""

        high_priority = [e for e in report['preview_entries'] if e['significance'] == 'high']
        for entry in high_priority:
            summary += f"- **{entry['file']}**: {entry['type']} (Confidence: {entry['confidence']:.2f})\n"

        summary += f"""

### ChittyLedger Integration Status
- **Ready for Minting:** {len([e for e in report['preview_entries'] if e['chittyledger_ready']])} files
- **Needs Review:** {len([e for e in report['preview_entries'] if not e['chittyledger_ready']])} files

## Next Steps
1. Review high-priority evidence items
2. Complete full pipeline processing with `/evidence-pipeline`
3. Verify chain of custody with `/integrity-check`

---
*This is an early preview. Full processing will analyze all evidence files.*
"""

        return summary


async def main():
    """Generate early preview of Flow of Funds evidence"""

    processor = FlowOfFundsProcessor()

    print("üîç Generating Early Preview of Flow of Funds Package")
    print("=" * 60)

    try:
        report = await processor.generate_early_preview()

        print(f"‚úÖ Preview Generated Successfully!")
        print(f"\nüìä Statistics:")
        print(f"   Files Processed: {report['statistics']['files_processed']}")
        print(f"   AI Enhanced: {report['statistics']['files_enhanced']}")
        print(f"   Ready for ChittyLedger: {report['statistics']['files_minted']}")

        print(f"\nüìÑ Reports saved to:")
        print(f"   JSON: flow_of_funds_preview.json")
        print(f"   Markdown: flow_of_funds_preview.md")

        print(f"\nüîç High Priority Evidence Found:")
        high_priority = [e for e in report['preview_entries'] if e['significance'] == 'high']
        for entry in high_priority[:5]:
            print(f"   ‚Ä¢ {entry['file']} (Confidence: {entry['confidence']:.2f})")

    except Exception as e:
        print(f"‚ùå Error generating preview: {e}")
        return 1

    return 0


if __name__ == "__main__":
    asyncio.run(main())